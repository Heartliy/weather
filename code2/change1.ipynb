{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       rain1h  rain24h  rain12h  rain6h  temperature  tempDiff  humidity  \\\n0         0.0   9999.0   9999.0  9999.0          6.0       NaN      34.0   \n1         0.0   9999.0   9999.0  9999.0          7.1       NaN      32.0   \n2         0.0   9999.0   9999.0  9999.0          7.9       NaN      31.0   \n3         0.0   9999.0   9999.0  9999.0          8.1       NaN      33.0   \n4         0.0   9999.0   9999.0  9999.0          6.7       NaN      38.0   \n...       ...      ...      ...     ...          ...       ...       ...   \n56395     0.0   9999.0   9999.0  9999.0          1.6       NaN      46.0   \n56396     0.0   9999.0   9999.0  9999.0          2.3       NaN      46.0   \n56397     0.0   9999.0   9999.0  9999.0          3.4       NaN      42.0   \n56398     0.0   9999.0   9999.0  9999.0          4.7       NaN      38.0   \n56399     0.0   9999.0   9999.0  9999.0          5.7       NaN      34.0   \n\n       pressure  windDirection  windSpeed              time city_code  \\\n0        1021.0          118.0        1.6  2023-12-09 17:00     54511   \n1        1020.0          166.0        2.5  2023-12-09 16:00     54511   \n2        1020.0          121.0        3.2  2023-12-09 15:00     54511   \n3        1019.0           82.0        1.6  2023-12-09 14:00     54511   \n4        1019.0          101.0        2.4  2023-12-09 13:00     54511   \n...         ...            ...        ...               ...       ...   \n56395     884.0          317.0        0.8  2023-12-08 22:00     51716   \n56396     883.0          357.0        1.4  2023-12-08 21:00     51716   \n56397     883.0           49.0        2.7  2023-12-08 20:00     51716   \n56398     882.0           39.0        1.5  2023-12-08 19:00     51716   \n56399     882.0           43.0        2.9  2023-12-08 18:00     51716   \n\n       province city_name  city_index  \n0           北京市        北京           1  \n1           北京市        北京           1  \n2           北京市        北京           1  \n3           北京市        北京           1  \n4           北京市        北京           1  \n...         ...       ...         ...  \n56395  新疆维吾尔自治区        巴楚        2350  \n56396  新疆维吾尔自治区        巴楚        2350  \n56397  新疆维吾尔自治区        巴楚        2350  \n56398  新疆维吾尔自治区        巴楚        2350  \n56399  新疆维吾尔自治区        巴楚        2350  \n\n[56400 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rain1h</th>\n      <th>rain24h</th>\n      <th>rain12h</th>\n      <th>rain6h</th>\n      <th>temperature</th>\n      <th>tempDiff</th>\n      <th>humidity</th>\n      <th>pressure</th>\n      <th>windDirection</th>\n      <th>windSpeed</th>\n      <th>time</th>\n      <th>city_code</th>\n      <th>province</th>\n      <th>city_name</th>\n      <th>city_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>6.0</td>\n      <td>NaN</td>\n      <td>34.0</td>\n      <td>1021.0</td>\n      <td>118.0</td>\n      <td>1.6</td>\n      <td>2023-12-09 17:00</td>\n      <td>54511</td>\n      <td>北京市</td>\n      <td>北京</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>7.1</td>\n      <td>NaN</td>\n      <td>32.0</td>\n      <td>1020.0</td>\n      <td>166.0</td>\n      <td>2.5</td>\n      <td>2023-12-09 16:00</td>\n      <td>54511</td>\n      <td>北京市</td>\n      <td>北京</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>7.9</td>\n      <td>NaN</td>\n      <td>31.0</td>\n      <td>1020.0</td>\n      <td>121.0</td>\n      <td>3.2</td>\n      <td>2023-12-09 15:00</td>\n      <td>54511</td>\n      <td>北京市</td>\n      <td>北京</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>8.1</td>\n      <td>NaN</td>\n      <td>33.0</td>\n      <td>1019.0</td>\n      <td>82.0</td>\n      <td>1.6</td>\n      <td>2023-12-09 14:00</td>\n      <td>54511</td>\n      <td>北京市</td>\n      <td>北京</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>6.7</td>\n      <td>NaN</td>\n      <td>38.0</td>\n      <td>1019.0</td>\n      <td>101.0</td>\n      <td>2.4</td>\n      <td>2023-12-09 13:00</td>\n      <td>54511</td>\n      <td>北京市</td>\n      <td>北京</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>56395</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>1.6</td>\n      <td>NaN</td>\n      <td>46.0</td>\n      <td>884.0</td>\n      <td>317.0</td>\n      <td>0.8</td>\n      <td>2023-12-08 22:00</td>\n      <td>51716</td>\n      <td>新疆维吾尔自治区</td>\n      <td>巴楚</td>\n      <td>2350</td>\n    </tr>\n    <tr>\n      <th>56396</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>2.3</td>\n      <td>NaN</td>\n      <td>46.0</td>\n      <td>883.0</td>\n      <td>357.0</td>\n      <td>1.4</td>\n      <td>2023-12-08 21:00</td>\n      <td>51716</td>\n      <td>新疆维吾尔自治区</td>\n      <td>巴楚</td>\n      <td>2350</td>\n    </tr>\n    <tr>\n      <th>56397</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>3.4</td>\n      <td>NaN</td>\n      <td>42.0</td>\n      <td>883.0</td>\n      <td>49.0</td>\n      <td>2.7</td>\n      <td>2023-12-08 20:00</td>\n      <td>51716</td>\n      <td>新疆维吾尔自治区</td>\n      <td>巴楚</td>\n      <td>2350</td>\n    </tr>\n    <tr>\n      <th>56398</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>4.7</td>\n      <td>NaN</td>\n      <td>38.0</td>\n      <td>882.0</td>\n      <td>39.0</td>\n      <td>1.5</td>\n      <td>2023-12-08 19:00</td>\n      <td>51716</td>\n      <td>新疆维吾尔自治区</td>\n      <td>巴楚</td>\n      <td>2350</td>\n    </tr>\n    <tr>\n      <th>56399</th>\n      <td>0.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>9999.0</td>\n      <td>5.7</td>\n      <td>NaN</td>\n      <td>34.0</td>\n      <td>882.0</td>\n      <td>43.0</td>\n      <td>2.9</td>\n      <td>2023-12-08 18:00</td>\n      <td>51716</td>\n      <td>新疆维吾尔自治区</td>\n      <td>巴楚</td>\n      <td>2350</td>\n    </tr>\n  </tbody>\n</table>\n<p>56400 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('D:\\pythonProject\\pyspark\\data\\passed_weather_ALL.csv')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "计算各城市过去24小时累积雨量"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, desc\n",
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.executorEnv.PYTHONHASHSEED\", \"0\") \\\n",
    "    .config(\"spark.hadoop.fs.file.impl\", \"org.apache.hadoop.fs.RawLocalFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "def passed_rain_analyse(filename):\n",
    "\n",
    "   print(\"开始分析累积降雨量\")\n",
    "   spark = SparkSession.builder.config(\"spark.hadoop.fs.file.impl\",\n",
    "                                       \"org.apache.hadoop.fs.RawLocalFileSystem\").getOrCreate()\n",
    "\n",
    "   # spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "   df = spark.read.csv(filename, header=True)\n",
    "\n",
    "   df_rain = df.select(col('province'), col('city_name'), col('city_code'),\n",
    "                    col('rain1h').cast(DecimalType(scale=1))).filter(col('rain1h') < 1000)\n",
    "\n",
    "   df_rain_sum = df_rain.groupBy(\"province\", \"city_name\", \"city_code\") \\\n",
    "      .agg(sum(\"rain1h\").alias(\"rain24h\")) \\\n",
    "      .sort(desc(\"rain24h\"))\n",
    "\n",
    "   # df_rain_sum.coalesce(1).write.mode(\"overwrite\").csv(\"passed_rain_analyse.csv\")\n",
    "\n",
    "   df_rain_sum.coalesce(1).write.csv(\"passed_rain_analyse.csv\")\n",
    "\n",
    "   print(\"累积降雨量分析完毕！\")\n",
    "\n",
    "   return df_rain_sum.head(20)  # 前20个\n",
    "\n",
    "passed_rain_analyse(\"passed_weather_ALL.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "计算各城市过去24小时平均气温"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始分析气温\n",
      "+------------+------------+---------+----------+---------------+\n",
      "|    province|   city_name|city_code|      date|avg_temperature|\n",
      "+------------+------------+---------+----------+---------------+\n",
      "|内蒙古自治区|        根河|    50431|2023-12-09|          -32.2|\n",
      "|    黑龙江省|        新林|    50349|2023-12-09|          -31.6|\n",
      "|    黑龙江省|        呼中|    50247|2023-12-09|          -30.6|\n",
      "|    黑龙江省|        漠河|    50136|2023-12-08|          -30.4|\n",
      "|内蒙古自治区|      图里河|    50434|2023-12-09|          -29.0|\n",
      "|内蒙古自治区|    额尔古纳|    50425|2023-12-09|          -28.7|\n",
      "|内蒙古自治区|新巴尔虎左旗|    50618|2023-12-09|          -27.8|\n",
      "|内蒙古自治区|      满洲里|    50514|2023-12-09|          -27.6|\n",
      "|内蒙古自治区|      阿尔山|    50727|2023-12-09|          -27.4|\n",
      "|内蒙古自治区|  陈巴尔虎旗|    50524|2023-12-09|          -27.4|\n",
      "|    黑龙江省|        漠河|    50136|2023-12-09|          -27.3|\n",
      "|内蒙古自治区|      牙克石|    50526|2023-12-09|          -27.1|\n",
      "|内蒙古自治区|      海拉尔|    50527|2023-12-09|          -27.1|\n",
      "|内蒙古自治区|    鄂温克旗|    50525|2023-12-09|          -26.7|\n",
      "|内蒙古自治区|      满洲里|    50514|2023-12-08|          -26.4|\n",
      "|    黑龙江省|        塔河|    50246|2023-12-09|          -26.2|\n",
      "|    黑龙江省|        呼玛|    50353|2023-12-09|          -26.2|\n",
      "|    黑龙江省|        新林|    50349|2023-12-08|          -25.2|\n",
      "|    黑龙江省|        塔河|    50246|2023-12-08|          -25.0|\n",
      "|内蒙古自治区|    鄂伦春旗|    50445|2023-12-09|          -25.0|\n",
      "+------------+------------+---------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "气温分析完毕\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(province='内蒙古自治区', city_name='根河', city_code='50431', date='2023-12-09', avg_temperature='-32.2'),\n Row(province='黑龙江省', city_name='新林', city_code='50349', date='2023-12-09', avg_temperature='-31.6'),\n Row(province='黑龙江省', city_name='呼中', city_code='50247', date='2023-12-09', avg_temperature='-30.6'),\n Row(province='黑龙江省', city_name='漠河', city_code='50136', date='2023-12-08', avg_temperature='-30.4'),\n Row(province='内蒙古自治区', city_name='图里河', city_code='50434', date='2023-12-09', avg_temperature='-29.0'),\n Row(province='内蒙古自治区', city_name='额尔古纳', city_code='50425', date='2023-12-09', avg_temperature='-28.7'),\n Row(province='内蒙古自治区', city_name='新巴尔虎左旗', city_code='50618', date='2023-12-09', avg_temperature='-27.8'),\n Row(province='内蒙古自治区', city_name='满洲里', city_code='50514', date='2023-12-09', avg_temperature='-27.6'),\n Row(province='内蒙古自治区', city_name='阿尔山', city_code='50727', date='2023-12-09', avg_temperature='-27.4'),\n Row(province='内蒙古自治区', city_name='陈巴尔虎旗', city_code='50524', date='2023-12-09', avg_temperature='-27.4'),\n Row(province='黑龙江省', city_name='漠河', city_code='50136', date='2023-12-09', avg_temperature='-27.3'),\n Row(province='内蒙古自治区', city_name='牙克石', city_code='50526', date='2023-12-09', avg_temperature='-27.1'),\n Row(province='内蒙古自治区', city_name='海拉尔', city_code='50527', date='2023-12-09', avg_temperature='-27.1'),\n Row(province='内蒙古自治区', city_name='鄂温克旗', city_code='50525', date='2023-12-09', avg_temperature='-26.7'),\n Row(province='内蒙古自治区', city_name='满洲里', city_code='50514', date='2023-12-08', avg_temperature='-26.4'),\n Row(province='黑龙江省', city_name='塔河', city_code='50246', date='2023-12-09', avg_temperature='-26.2'),\n Row(province='黑龙江省', city_name='呼玛', city_code='50353', date='2023-12-09', avg_temperature='-26.2'),\n Row(province='黑龙江省', city_name='新林', city_code='50349', date='2023-12-08', avg_temperature='-25.2'),\n Row(province='黑龙江省', city_name='塔河', city_code='50246', date='2023-12-08', avg_temperature='-25.0'),\n Row(province='内蒙古自治区', city_name='鄂伦春旗', city_code='50445', date='2023-12-09', avg_temperature='-25.0')]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, desc\n",
    "from pyspark.sql.types import DecimalType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkConf\n",
    "\n",
    "# 其他代码...\n",
    "\n",
    "\n",
    "# 其他代码...\n",
    "\n",
    "\n",
    "def passed_temperature_analyse(filename):\n",
    "\n",
    "    print(\"开始分析气温\")\n",
    "\n",
    "    # spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()\n",
    "    spark_conf = SparkConf().setAppName(\"TemperatureAnalysis\").setMaster(\"local[*]\")\n",
    "    spark = SparkSession.builder.config(conf=spark_conf).getOrCreate()\n",
    "\n",
    "\n",
    "    df = spark.read.csv(filename, header=True)\n",
    "\n",
    "    df_temperature = df.select(  # 选择需要的列\n",
    "\n",
    "        df['province'],\n",
    "\n",
    "        df['city_name'],\n",
    "\n",
    "        df['city_code'],\n",
    "\n",
    "        df['temperature'].cast(DecimalType(scale=1)),  # 转换为十进制类型，并将小数点后的位数保留1位\n",
    "\n",
    "        F.date_format(df['time'], \"yyyy-MM-dd\").alias(\"date\"),  # 得到日期数据\n",
    "\n",
    "        F.hour(df['time']).alias(\"hour\")  # 得到小时数据，命名为hour\n",
    "\n",
    "    ).filter(df['temperature'] < 1000)\n",
    "\n",
    "    # 筛选四点时次\n",
    "\n",
    "    df_4point_temperature = df_temperature.filter(df_temperature['hour'].isin([2, 8, 14, 20]))\n",
    "\n",
    "    df_avg_temperature = df_4point_temperature.groupBy(\"province\", \"city_name\", \"city_code\", \"date\").agg(F.count(\"temperature\"), F.avg(\"temperature\").alias(\"avg_temperature\")).sort(F.asc(\"avg_temperature\")).select(\"province\", \"city_name\", \"city_code\", \"date\",F.format_number('avg_temperature', 1).alias(\"avg_temperature\"))\n",
    "\n",
    "    df_avg_temperature.show()\n",
    "\n",
    "    avg_temperature_list = df_avg_temperature.collect()\n",
    "\n",
    "    # df_avg_temperature.coalesce(1).write.csv(\"passed_temperature.csv\")\n",
    "    output_path = \"D:/pythonProject/pyspark/code/passed_temperature.csv\"\n",
    "\n",
    "    df_avg_temperature.coalesce(1).write.csv(output_path)\n",
    "\n",
    "    print(\"气温分析完毕\")\n",
    "\n",
    "    return avg_temperature_list[0:20]  # 前20个\n",
    "passed_temperature_analyse(\"passed_weather_ALL.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "计算各城市过去24小时平均气压"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始分析气压\n",
      "气压分析完毕\n"
     ]
    },
    {
     "data": {
      "text/plain": "[Row(province='西藏自治区', city_name='珠峰大本营', city_code='55656', date='2023-12-09', avg_pressure='551.0'),\n Row(province='西藏自治区', city_name='珠峰大本营', city_code='55656', date='2023-12-08', avg_pressure='552.0'),\n Row(province='西藏自治区', city_name='双湖', city_code='55178', date='2023-12-09', avg_pressure='552.3'),\n Row(province='西藏自治区', city_name='双湖', city_code='55178', date='2023-12-08', avg_pressure='554.0'),\n Row(province='西藏自治区', city_name='班戈', city_code='55279', date='2023-12-09', avg_pressure='569.3'),\n Row(province='西藏自治区', city_name='安多', city_code='55294', date='2023-12-09', avg_pressure='571.0'),\n Row(province='西藏自治区', city_name='班戈', city_code='55279', date='2023-12-08', avg_pressure='572.0'),\n Row(province='西藏自治区', city_name='措勤', city_code='55357', date='2023-12-09', avg_pressure='572.0'),\n Row(province='西藏自治区', city_name='措勤', city_code='55357', date='2023-12-08', avg_pressure='573.0'),\n Row(province='西藏自治区', city_name='安多', city_code='55294', date='2023-12-08', avg_pressure='573.0'),\n Row(province='西藏自治区', city_name='申扎', city_code='55472', date='2023-12-09', avg_pressure='573.3'),\n Row(province='西藏自治区', city_name='聂荣', city_code='55298', date='2023-12-09', avg_pressure='575.0'),\n Row(province='西藏自治区', city_name='申扎', city_code='55472', date='2023-12-08', avg_pressure='576.0'),\n Row(province='西藏自治区', city_name='聂荣', city_code='55298', date='2023-12-08', avg_pressure='577.0'),\n Row(province='西藏自治区', city_name='尼玛', city_code='55361', date='2023-12-09', avg_pressure='579.3'),\n Row(province='西藏自治区', city_name='尼玛', city_code='55361', date='2023-12-08', avg_pressure='581.0'),\n Row(province='西藏自治区', city_name='岗巴', city_code='55677', date='2023-12-09', avg_pressure='581.3'),\n Row(province='西藏自治区', city_name='岗巴', city_code='55677', date='2023-12-08', avg_pressure='582.0'),\n Row(province='西藏自治区', city_name='仲巴', city_code='55542', date='2023-12-09', avg_pressure='583.7'),\n Row(province='西藏自治区', city_name='革吉', city_code='55234', date='2023-12-08', avg_pressure='584.0')]"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def passed_pressure_analyse(filename):\n",
    "\n",
    "    print(\"开始分析气压\")\n",
    "\n",
    "    spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()\n",
    "\n",
    "    df = spark.read.csv(filename, header=True)\n",
    "\n",
    "    df_pressure = df.select(  # 选择需要的列\n",
    "\n",
    "        df['province'],\n",
    "\n",
    "        df['city_name'],\n",
    "\n",
    "        df['city_code'],\n",
    "\n",
    "        df['pressure'].cast(DecimalType(scale=1)),\n",
    "\n",
    "        F.date_format(df['time'], \"yyyy-MM-dd\").alias(\"date\"),  # 得到日期数据\n",
    "\n",
    "        F.hour(df['time']).alias(\"hour\")  # 得到小时数据\n",
    "\n",
    "    )\n",
    "\n",
    "    df_4point_pressure = df_pressure.filter(df_pressure['hour'].isin([2, 8, 14, 20]))\n",
    "\n",
    "    df_avg_pressure = df_4point_pressure.groupBy(\"province\", \"city_name\", \"city_code\", \"date\").agg(\n",
    "\n",
    "        F.count(\"pressure\"), F.avg(\"pressure\").alias(\"avg_pressure\")).sort(\n",
    "\n",
    "        F.asc(\"avg_pressure\")).select(\"province\", \"city_name\", \"city_code\", \"date\",\n",
    "\n",
    "                                      F.format_number('avg_pressure', 1).alias(\"avg_pressure\"))\n",
    "\n",
    "    avg_pressure_list = df_avg_pressure.collect()\n",
    "\n",
    "    df_avg_pressure.coalesce(1).write.csv(\"passed_pressure.csv\")\n",
    "\n",
    "    print(\"气压分析完毕\")\n",
    "\n",
    "    return avg_pressure_list[0:20]  # 最低的20个\n",
    "passed_pressure_analyse('passed_weather_ALL.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
